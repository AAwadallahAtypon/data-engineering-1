{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99edfaac-0413-459b-bcd6-f08170135b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/dags/assignment_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/dags/assignment_2.py\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "host = \"postgres_storage\"\n",
    "database = \"csv_db\"\n",
    "user = \"aawadallah\"\n",
    "password = \"1234\"\n",
    "port = '5432'\n",
    "\n",
    "\n",
    "engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "def Get_DF_i(Day):\n",
    "    DF_i=None\n",
    "    \n",
    "    try: \n",
    "        URL_Day=f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{Day}'\n",
    "        DF_day=pd.read_csv(URL_Day)\n",
    "        DF_day['Day']=Day.split('.')[0]\n",
    "        cond=(DF_day.Country_Region=='Germany')&(DF_day.Province_State=='Berlin')\n",
    "        Selec_columns=['Day','Country_Region', 'Last_Update',\n",
    "          'Lat', 'Long_', 'Confirmed', 'Deaths', 'Recovered', 'Active',\n",
    "          'Combined_Key', 'Incident_Rate', 'Case_Fatality_Ratio']\n",
    "        DF_i=DF_day[cond][Selec_columns].reset_index(drop=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return DF_i\n",
    "\n",
    "\n",
    "\n",
    "def _fetch_data_as_DF(**context):\n",
    "    # this to grep all the files names  from the repo \n",
    "    CMD = \"curl -s https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports | grep -Eo '[0-9-]*.csv' | sort -Vu\"\n",
    "    output = subprocess.check_output(CMD, shell=True)\n",
    "    List_of_days = output.decode('utf-8').split('\\n')\n",
    "    List_of_days = [line for line in List_of_days if line.strip() != \"\"]\n",
    "    #Appending all data. \n",
    "    # lst_all_DFs= multiprocessing.Pool().map(Get_DF_i, List_of_days)  I've tried to multiprocce the data but seems like it's not allowed in airflow,\n",
    "    #AssertionError: daemonic processes are not allowed to have children\n",
    "    \n",
    "    lst_all_DFs=[]\n",
    "    for Day in List_of_days:\n",
    "        lst_all_DFs.append(Get_DF_i(Day))\n",
    "    \n",
    "    #ConvertList to DF \n",
    "    DF_all = pd.concat(lst_all_DFs).reset_index(drop=True)\n",
    "    DF_all.to_csv('/home/sharedVol/data.csv')\n",
    "\n",
    "\n",
    "\n",
    "def _minMax_scale_data(**context):\n",
    "    DF_Germany=pd.read_csv('/home/sharedVol/data.csv')\n",
    "    Selec_Columns=['Confirmed','Deaths', 'Recovered', 'Active', 'Incident_Rate','Case_Fatality_Ratio']\n",
    "    DF_Germany_2 = DF_Germany[Selec_Columns]\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    DF_Germany_3 = pd.DataFrame(min_max_scaler.fit_transform(DF_Germany_2),columns=Selec_Columns)\n",
    "    DF_Germany_3.index=DF_Germany_2.index\n",
    "    DF_Germany_3['Day']=DF_Germany.Day\n",
    "    DF_Germany_3.to_csv('/home/sharedVol/Scaleddata.csv')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def _push_data_to_postgress_and_Plot(**context):\n",
    "    DF_Germany=pd.read_csv('/home/sharedVol/data.csv')\n",
    "    DF_Germany_3=pd.read_csv('/home/sharedVol/Scaleddata.csv')\n",
    "    DF_Germany.to_sql('data_without_scaling', engine,if_exists='replace',index=False)\n",
    "    DF_Germany_3.to_sql('data_with_scaling', engine,if_exists='replace',index=False)\n",
    "    \n",
    "    import matplotlib.pyplot as plt \n",
    "    import matplotlib\n",
    "    font = {'weight' : 'bold',\n",
    "            'size'   : 18}\n",
    "\n",
    "    matplotlib.rc('font', **font)\n",
    "    Selec_Columns=['Confirmed','Deaths', 'Recovered', 'Active', 'Incident_Rate','Case_Fatality_Ratio']\n",
    "    DF_Germany_3[Selec_Columns].plot(figsize=(20,10))\n",
    "    plt.savefig('/home/output/germany_scoring_report.png')\n",
    "    DF_Germany_3.to_csv('/home/output/germany_scoring_report.csv')\n",
    "    \n",
    "\n",
    "\n",
    "def _install_tools():\n",
    "\n",
    "    try:\n",
    "        import psycopg2\n",
    "    except:\n",
    "        subprocess.check_call(['pip', 'install', 'psycopg2-binary'])\n",
    "        import psycopg2\n",
    "\n",
    "    try:\n",
    "        from sqlalchemy import create_engine\n",
    "    except:\n",
    "        subprocess.check_call(['pip', 'install', 'sqlalchemy'])\n",
    "        from sqlalchemy import create_engine\n",
    "        \n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except:\n",
    "        subprocess.check_call(['pip', 'install', 'pandas'])\n",
    "        import pandas as pd\n",
    "        \n",
    "    try:\n",
    "        import matplotlib \n",
    "    except:\n",
    "        subprocess.check_call(['pip', 'install', 'matplotlib'])\n",
    "        import matplotlib\n",
    "        \n",
    "    try:\n",
    "        import sklearn \n",
    "    except:\n",
    "        subprocess.check_call(['pip', 'install', 'sklearn'])\n",
    "        import sklearn        \n",
    "\n",
    "\n",
    "\n",
    "with DAG(\"ETL_JHC\", start_date=datetime(2021, 1, 1),\n",
    "         schedule_interval=\"0 1 * * *\", catchup=False) as dag: #to run it everyday at 1 PM\n",
    "    install_tools = PythonOperator(\n",
    "        task_id=\"install_tools\",\n",
    "        python_callable=_install_tools,\n",
    "        provide_context=True\n",
    "    )\n",
    "    \n",
    "    fetchData = PythonOperator(\n",
    "        task_id=\"fetch_data_and_save_it_to_filesystem\",\n",
    "        python_callable=_fetch_data_as_DF,\n",
    "        provide_context=True\n",
    "    )\n",
    "\n",
    "    minMaxScaleData = PythonOperator(\n",
    "        task_id=\"minMax_Scale_data\",\n",
    "        python_callable=_minMax_scale_data,\n",
    "        provide_context=True\n",
    "    )\n",
    "\n",
    "    pushDataToPG = PythonOperator(\n",
    "        task_id=\"push_data_to_postgress_and_polt_report\",\n",
    "        python_callable=_push_data_to_postgress_and_Plot,\n",
    "        provide_context=True\n",
    "    )\n",
    "\n",
    "    install_tools >> fetchData >> minMaxScaleData >> pushDataToPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896024e3-eeec-43a0-bf4b-a67286fbd048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-8.4.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 497 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/lib/python3.8/site-packages (from faker) (2.8.1)\n",
      "Collecting text-unidecode==1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.4->faker) (1.15.0)\n",
      "Installing collected packages: text-unidecode, faker\n",
      "Successfully installed faker-8.4.0 text-unidecode-1.3\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.8.6-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 760 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.8.6\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 477 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 545 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.20.3)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.2.0-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 309 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.2 pillow-8.2.0\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 438 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.2 MB 633 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 681 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=d76b47a4891d66d4c184bbcc761e01d234593904ae74e1e75fc80540fbf95178\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.2 scipy-1.6.3 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from faker import Faker\n",
    "except:\n",
    "   !pip install faker \n",
    "   from faker import Faker\n",
    "    \n",
    "try:\n",
    "    import psycopg2 \n",
    "except:\n",
    "    !pip install psycopg2-binary \n",
    "    import psycopg2\n",
    "    \n",
    "try:\n",
    "    from sqlalchemy import create_engine\n",
    "except:\n",
    "    !pip install sqlalchemy\n",
    "    from sqlalchemy import create_engine\n",
    "    \n",
    "    \n",
    "try:\n",
    "    import pandas as pd \n",
    "except:\n",
    "    !pip install pandas\n",
    "    import pandas as pd \n",
    "     \n",
    "try:\n",
    "    import matplotlib \n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "\n",
    "try:\n",
    "    import sklearn \n",
    "except:\n",
    "    !pip install sklearn\n",
    "    import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f7492e-426e-4412-9856-e9f04779eeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Incident_Rate</th>\n",
       "      <th>Case_Fatality_Ratio</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.414843</td>\n",
       "      <td>0.306822</td>\n",
       "      <td>0.365525</td>\n",
       "      <td>0.788300</td>\n",
       "      <td>0.264754</td>\n",
       "      <td>0.389571</td>\n",
       "      <td>01-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.418180</td>\n",
       "      <td>0.309337</td>\n",
       "      <td>0.367915</td>\n",
       "      <td>0.793958</td>\n",
       "      <td>0.266884</td>\n",
       "      <td>0.390960</td>\n",
       "      <td>01-02-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.422938</td>\n",
       "      <td>0.315624</td>\n",
       "      <td>0.375865</td>\n",
       "      <td>0.765119</td>\n",
       "      <td>0.269921</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>01-03-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.428531</td>\n",
       "      <td>0.322540</td>\n",
       "      <td>0.383254</td>\n",
       "      <td>0.746993</td>\n",
       "      <td>0.273490</td>\n",
       "      <td>0.407042</td>\n",
       "      <td>01-04-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.437490</td>\n",
       "      <td>0.342345</td>\n",
       "      <td>0.392163</td>\n",
       "      <td>0.739907</td>\n",
       "      <td>0.279207</td>\n",
       "      <td>0.438756</td>\n",
       "      <td>01-05-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.446963</td>\n",
       "      <td>0.359635</td>\n",
       "      <td>0.400894</td>\n",
       "      <td>0.738588</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.463639</td>\n",
       "      <td>01-06-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.458345</td>\n",
       "      <td>0.372839</td>\n",
       "      <td>0.408365</td>\n",
       "      <td>0.762538</td>\n",
       "      <td>0.292517</td>\n",
       "      <td>0.476751</td>\n",
       "      <td>01-07-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.469073</td>\n",
       "      <td>0.391701</td>\n",
       "      <td>0.414076</td>\n",
       "      <td>0.794672</td>\n",
       "      <td>0.299364</td>\n",
       "      <td>0.502086</td>\n",
       "      <td>01-08-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.474383</td>\n",
       "      <td>0.395787</td>\n",
       "      <td>0.418226</td>\n",
       "      <td>0.800879</td>\n",
       "      <td>0.302753</td>\n",
       "      <td>0.503531</td>\n",
       "      <td>01-09-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.476849</td>\n",
       "      <td>0.397359</td>\n",
       "      <td>0.427539</td>\n",
       "      <td>0.744576</td>\n",
       "      <td>0.304327</td>\n",
       "      <td>0.503524</td>\n",
       "      <td>01-10-2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Confirmed    Deaths  Recovered    Active  Incident_Rate  \\\n",
       "0           0   0.414843  0.306822   0.365525  0.788300       0.264754   \n",
       "1           1   0.418180  0.309337   0.367915  0.793958       0.266884   \n",
       "2           2   0.422938  0.315624   0.375865  0.765119       0.269921   \n",
       "3           3   0.428531  0.322540   0.383254  0.746993       0.273490   \n",
       "4           4   0.437490  0.342345   0.392163  0.739907       0.279207   \n",
       "5           5   0.446963  0.359635   0.400894  0.738588       0.285253   \n",
       "6           6   0.458345  0.372839   0.408365  0.762538       0.292517   \n",
       "7           7   0.469073  0.391701   0.414076  0.794672       0.299364   \n",
       "8           8   0.474383  0.395787   0.418226  0.800879       0.302753   \n",
       "9           9   0.476849  0.397359   0.427539  0.744576       0.304327   \n",
       "\n",
       "   Case_Fatality_Ratio         Day  \n",
       "0             0.389571  01-01-2021  \n",
       "1             0.390960  01-02-2021  \n",
       "2             0.398892  01-03-2021  \n",
       "3             0.407042  01-04-2021  \n",
       "4             0.438756  01-05-2021  \n",
       "5             0.463639  01-06-2021  \n",
       "6             0.476751  01-07-2021  \n",
       "7             0.502086  01-08-2021  \n",
       "8             0.503531  01-09-2021  \n",
       "9             0.503524  01-10-2021  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "host = \"postgres_storage\"\n",
    "database = \"csv_db\"\n",
    "user = \"aawadallah\"\n",
    "password = \"1234\"\n",
    "port = '5432'\n",
    "\n",
    "\n",
    "engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "\n",
    "scores_extracted=pd.read_sql(\"SELECT * FROM data_with_scaling\" , engine);\n",
    "scores_extracted.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf58370-5579-47ca-9030-6a8987d5dc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
